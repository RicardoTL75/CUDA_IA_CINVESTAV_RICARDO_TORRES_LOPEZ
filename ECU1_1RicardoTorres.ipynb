{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM3j11tyDvvQAC2y98gKe1b"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":20,"metadata":{"id":"5MXWMifO7R2H","executionInfo":{"status":"ok","timestamp":1762633055229,"user_tz":420,"elapsed":108,"user":{"displayName":"Ricardo Torres","userId":"06553239871648539140"}}},"outputs":[],"source":["!uv pip install -q --system numba-cuda==0.4.0\n","import numpy as np\n","from numba import cuda\n","import time\n","import os\n","from numba import config\n","config.CUDA_ENABLE_PYNVJITLINK = 1"]},{"cell_type":"code","source":["# CUDA Steps:\n","# Initializing data from CPU\n","# Transfer from CPU to GPU\n","# Run kernel with defined Grid/Block size (Threads)\n","# Transfer results from GPU to CPU\n","# Clear memory\n","\n","#  CUDA kernel\n","@cuda.jit\n","def first_kernel(a, result):\n","  idx = cuda.grid(1)\n","  if idx < a.size:\n","    result[idx] = a[idx]\n","\n","\n","# Host\n","def main():\n","  # 1. Initialize data on CPU\n","  N = 10_000_000\n","  a_cpu = np.arange(N, dtype = np.float32)\n","\n","  # -----------------------------------\n","  # CPU computation\n","  # -----------------------------------\n","  start = time.time()\n","  result_cpu = a_cpu\n","  cpu_time = time.time() - start\n","  print(f\"CPU time: {cpu_time * 1e6:.2f} micro seg\")\n","\n","\n","  # -----------------------------------\n","  # GPU computation\n","  # -----------------------------------\n","  # 2.- Transfer from CPU to GPU\n","  start = time.time()\n","  a_gpu = cuda.to_device(a_cpu)\n","  result_gpu = cuda.device_array_like(a_cpu) # Reserve memory\n","  transfer_in_time = time.time() - start\n","\n","  # Kernel launch\n","  threads_per_block = 128\n","  blocks_per_grid = (N + threads_per_block - 1) // threads_per_block #78,125 hilos\n","  start = time.time()\n","  first_kernel[blocks_per_grid, threads_per_block](a_gpu, result_gpu) # Launch kernel\n","  cuda.synchronize()\n","  kernel_time = time.time() - start\n","\n","  # Copy back\n","  start = time.time()\n","  result_from_gpu = result_gpu.copy_to_host()\n","  cuda.synchronize()\n","  transfer_out_time = time.time() - start\n","\n","  # Report\n","  print(f\"GPU transfer to device: {transfer_in_time * 1e3:.2f} ms\")\n","  print(f\"GPU kernel execution: {kernel_time * 1e3:.2f} ms\")\n","  print(f\"GPU transfer to host: {transfer_out_time * 1e3:.2f} ms\")\n","  print(f\"Total GPU time: {(transfer_in_time + kernel_time + transfer_out_time) * 1e3:.2f} ms\")\n","\n","  # Cleanup\n","  del a_gpu, result_gpu\n","  cuda.close()\n","\n","\n","if __name__ == \"__main__\":\n","  main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FTiKNscB9dPH","executionInfo":{"status":"ok","timestamp":1762633055479,"user_tz":420,"elapsed":236,"user":{"displayName":"Ricardo Torres","userId":"06553239871648539140"}},"outputId":"ba5c582c-257c-442d-d53a-7a9f6dd01fad"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU time: 1.43 micro seg\n","GPU transfer to device: 101.48 ms\n","GPU kernel execution: 43.72 ms\n","GPU transfer to host: 14.70 ms\n","Total GPU time: 159.90 ms\n"]}]}]}