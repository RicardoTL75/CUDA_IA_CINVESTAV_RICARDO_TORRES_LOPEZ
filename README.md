# CUDA_IA_CINVESTAV_RICARDO_TORRES_LOPEZ
CUDA_1, CUDA_2 AND CUDA_3

ğŸ“Š Reporte TÃ©cnico: ProgramaciÃ³n CUDA con Numba
ğŸ“‹ IntroducciÃ³n
Este reporte documenta el trabajo realizado en tres ejercicios de programaciÃ³n paralela utilizando CUDA con Numba para ejecuciÃ³n en GPUs NVIDIA. Los cÃ³digos implementan desde operaciones bÃ¡sicas hasta algoritmos complejos de procesamiento de imÃ¡genes.

https://via.placeholder.com/800x200/4A90E2/FFFFFF?text=CUDA+Architecture+Grids+Blocks+Threads

ğŸš€ ECU1 - Fundamentos de CUDA y Transferencia de Datos
ğŸ¯ Objetivo
Implementar un kernel CUDA bÃ¡sico para comprender el flujo de trabajo CPU-GPU y medir los tiempos de transferencia.

ğŸ”§ ImplementaciÃ³n
@cuda.jit
def first_kernel(a, result):
    idx = cuda.grid(1)
    if idx < a.size:
        result[idx] = a[idx]

ğŸ“Š Arquitectura de EjecuciÃ³n
CPU Data > Transfer GPU > Kernel Execution > Transfer CPU > CPU Result

â±ï¸ Resultados de Performance
OperaciÃ³n	Tiempo	Porcentaje
CPU Computation	1.43 Î¼s	-
GPU Transfer to Device	101.48 ms	63%
GPU Kernel Execution	43.72 ms	27%
GPU Transfer to Host	14.70 ms	9%
Total GPU Time	159.90 ms	100%

ğŸ“ˆ AnÃ¡lisis
ğŸ”„ Proceso GPU vs CPU:
â”œâ”€â”€ âš¡ CPU: Procesamiento inmediato (1.43Î¼s)
â””â”€â”€ ğŸ¯ GPU: Overhead significativo por transferencias
    â”œâ”€â”€ ğŸ“¤ Entrada: 101.48ms (63%)
    â”œâ”€â”€ âš™ï¸ Procesamiento: 43.72ms (27%)
    â””â”€â”€ ğŸ“¥ Salida: 14.70ms (9%)
ConclusiÃ³n: Las transferencias de datos representan el mayor costo temporal, destacando la importancia de minimizar comunicaciones CPU-GPU.

ğŸ§® ECU2 - Modelo de Hilos y Dimensiones
ğŸ¯ Objetivo
Explorar la organizaciÃ³n jerÃ¡rquica de hilos en CUDA (Grids, Blocks, Threads).

ğŸ”§ Conceptos Clave
Ejemplo 1: 1 Bloque Ã— 8 Threads
Grid: [1 bloque]
Block: [8 threads]
Total: 8 hilos

Ejemplo 2: 2 Bloques Ã— 4 Threads
Grid: [2 bloques]
Block: [4 threads cada uno]
Total: 8 hilos

ğŸ—ï¸ Estructura 2D/3D
# ConfiguraciÃ³n 2D
blocks_per_grid = (2, 2)      # 4 bloques total
threads_per_block = (4, 1)    # 4 hilos por bloque
# Total: 16 hilos

ğŸ“ FÃ³rmulas de IndexaciÃ³n
Global ID = Block ID Ã— Threads per Block + Thread ID
Block ID = blockIdx.x + blockIdx.y Ã— gridDim.x
Thread Offset = threadIdx.x + threadIdx.y Ã— blockDim.x

ğŸª VisualizaciÃ³n de EjecuciÃ³n 2D
Ejemplo 2D (2Ã—2 bloques, 4Ã—1 threads):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Bloque (0,0)â”‚ Bloque (1,0)â”‚
â”‚ T0 T1 T2 T3 â”‚ T0 T1 T2 T3 â”‚
â”‚ G0 G1 G2 G3 â”‚ G4 G5 G6 G7 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Bloque (0,1)â”‚ Bloque (1,1)â”‚
â”‚ T0 T1 T2 T3 â”‚ T0 T1 T2 T3 â”‚
â”‚ G8 G9 G10 G11â”‚ G12 G13 G14 G15â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ”¢ Salida del Kernel Whoami
020 | Block[x,y](0 0) = 4 | Thread[x,y](0 0) = 4
021 | Block[x,y](0 0) = 4 | Thread[x,y](1 0) = 5
...
035 | Block[x,y](1 1) = 7 | Thread[x,y](3 0) = 7

ObservaciÃ³n: Se evidencia el cÃ¡lculo correcto de IDs globales a partir de las coordenadas 2D.

âš¡ ECU3 - Algoritmos Paralelos Avanzados
ğŸ¯ Objetivo
Implementar algoritmos computacionalmente intensivos y comparar performance CPU vs GPU.

ğŸ“Š Benchmark de Algoritmos
1. ğŸ§® Vector Addition
@cuda.jit
def vector_add_kernel(a, b, c):
    idx = cuda.grid(1)
    if idx < c.size:
        c[idx] = a[idx] + b[idx]

âš¡ Resultados:
ğŸ¯ GPU: ~2.5ms
ğŸ’» CPU NumPy: ~15ms
ğŸš€ Speedup: 6x

2. ğŸ“ Matrix Scaling (2D)
@cuda.jit
def matrix_scale_kernel(mat, scalar, out):
    row, col = cuda.grid(2)
    if row < out.shape[0] and col < out.shape[1]:
        out[row, col] = mat[row, col] * scalar

ConfiguraciÃ³n:

Matriz: 4096Ã—4096 (16.7M elementos)
Threads: (32, 32) por bloque
Blocks: (128, 128) en grid

âš¡ Resultados:
ğŸ¯ GPU: ~15ms
ğŸ’» CPU NumPy: ~45ms
ğŸš€ Speedup: 3x

3. ğŸ”¢ Matrix Multiplication
@cuda.jit
def matmul_naive_kernel(A, B, C):
    row, col = cuda.grid(2)
    if row < M and col < N:
        total = 0.0
        for k in range(K):
            total += A[row, k] * B[k, col]
        C[row, col] = total

âš¡ Resultados:
ğŸ¯ GPU: ~250ms
ğŸ’» CPU NumPy: ~500ms
ğŸš€ Speedup: 2x

4. ğŸ–¼ï¸ Sobel Edge Detection
@cuda.jit
def sobel_kernel(img, out):
    row, col = cuda.grid(2)
    if 0 < row < H-1 and 0 < col < W-1:
        # CÃ¡lculo de gradientes Gx y Gy
        gx = (-img[row-1,col-1] + img[row-1,col+1] 
              -2*img[row,col-1] + 2*img[row,col+1]
              -img[row+1,col-1] + img[row+1,col+1])
        gy = (-img[row-1,col-1] - 2*img[row-1,col] - img[row-1,col+1]
              + img[row+1,col-1] + 2*img[row+1,col] + img[row+1,col+1])
        out[row, col] = (gx*gx + gy*gy)**0.5

âš¡ Resultados (Imagen 4K):
ğŸ¯ GPU: ~8ms
ğŸ’» CPU OpenCV: ~25ms
ğŸš€ Speedup: 3.1x

ğŸ“ˆ Resumen Comparativo de Performance
graph TD
    A[Operaciones CUDA] --> B[Vector Add]
    A --> C[Matrix Scale]
    A --> D[Matrix Multiply]
    A --> E[Sobel Filter]
    
    B --> F[Speedup: 6x]
    C --> G[Speedup: 3x]
    D --> H[Speedup: 2x]
    E --> I[Speedup: 3.1x]

ğŸ¯ AnÃ¡lisis de Patrones de Acceso
Algoritmo	PatrÃ³n Acceso	Eficiencia	Bottleneck
Vector Add	Coalescido	Alta	Ancho de banda
Matrix Scale	Coalescido	Alta	Ancho de banda
Matrix Mult	EstrÃ­ado	Media	Latencia memoria
Sobel	Local	Alta	CÃ¡lculos

ğŸ† Conclusiones Generales
âœ… Logros Alcanzados
ğŸ¯ Dominio Conceptual: ComprensiÃ³n profunda del modelo de programaciÃ³n CUDA
âš¡ OptimizaciÃ³n: ImplementaciÃ³n eficiente de kernels para diferentes cargas de trabajo
ğŸ“Š AnÃ¡lisis: Capacidad para identificar cuellos de botella y oportunidades de optimizaciÃ³n
ğŸ› ï¸ Versatilidad: AplicaciÃ³n en mÃºltiples dominios (Ã¡lgebra lineal, procesamiento de imÃ¡genes)

ğŸ”§ Lecciones Aprendidas
Las transferencias CPU-GPU son costosas â†’ Minimizar comunicaciones
La organizaciÃ³n de hilos afecta performance â†’ Elegir grid/block size apropiado
Patrones de acceso a memoria son cruciales â†’ Buscar coalescencia
Kernels simples pueden superar a CPU para operaciones paralelizables

ğŸš€ Recomendaciones para Futuros Trabajos
Usar memoria compartida para algoritmos como matrix multiplication
Implementar tiling para mejor utilizaciÃ³n de cachÃ©
Experimentar con diferentes configuraciones de blocks/threads
Considerar uso de streams para operaciones concurrentes

ğŸ“š Recursos TÃ©cnicos
ğŸ”— LibrerÃ­as Utilizadas
numba-cuda==0.4.0
numpy
opencv-python
pynvjitlink-cu12

ğŸ–¥ï¸ Hardware
GPU: NVIDIA T4
Entorno: Google Colab

ğŸ“– Referencias
DocumentaciÃ³n oficial de Numba CUDA
NVIDIA CUDA Programming Guide
Best Practices for CUDA C++ Programming
-------------------------------------------------------------
ğŸ“ Elaborado por: Ricardo Torres
ğŸ“… Fecha: Noviembre 2024
ğŸ·ï¸ TecnologÃ­as: CUDA, Numba, Python, NVIDIA GPU